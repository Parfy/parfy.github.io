---
layout: project
permalink: /:title/
category: projects

meta:
  keywords: "audio analysis, python, p5js, audio visualization"

project:
  title: "Audio visualisation with python and p5js"
  type: "Creative Coding"
  url: "/colab-music-feature-extraction/"
  logo: "/assets/images/projects/audioanalysis/audiowave_icon.png"
  tech: "python, p5js, essentia, colab"
  code: "https://github.com/Parfy/colab-music-feature-extraction/"
  demo: "https://parfy.github.io/colab-music-feature-extraction/Audio%20Wave%20Viz/index.html"

images:
  - image:
    url: "/assets/images/projects/audioanalysis/AudioWave.png"
    alt: "Audio analysis with python and p5js"
  - image:
    url: "/assets/images/projects/audioanalysis/code.png"
    alt: "Audio analysis with python and p5js"
  - image:
    url: "/assets/images/projects/audioanalysis/AudioWaveYellow.png"
    alt: "Audio analysis with python and p5js"
---
<p>The project analyses a music track with python to extract features such as beats and pitch. The output from the analysis is then visualised live while the track plays. The idea is that a lot of the features of a music track that we recognise as humans can't be detected programmatically in realtime and instead need to be extracted offline.</p>
